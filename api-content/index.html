{"posts":[{"title":"作品展示——儿童短视频社区","content":"这是今年4月份设计的新产品，后来由于短视频接口（字节火山引擎）太贵的原因，没能落地实现。 现在看来，其中广场部分的设计还是显露了toC产品经验不足的问题。但后续拍摄流程展示和设计的比较完整，基本完成了设计目标。 ","link":"https://sxk13.github.io/pmfun.github.io/post/zuo-pin-zhan-shi-er-tong-duan-shi-pin-she-qu/"},{"title":"【玩儿】Python爬取索尼E口和M4/3口镜头列表","content":"由于精力和冲洗空间的限制，我爬出胶片坑已经一年多了。但是最近手痒难耐，不禁想跳回摄影坑，于是挑选器材提上了日程。 首先映入眼帘的是M4/3系统和索尼α7系列，分别以便携和全画幅的优势进入了待选列表。那么接下来就是镜头群的问题啦。 项目页面见此处--&gt;Github页面 页面分析 数据来源选择了太平洋电脑网，选择的原因有三： 镜头列表中有足够的数据，无需进入详情页面获取； 列表中包含报价信息，方便之后与闲鱼价格对比； 懒得找其他网站了，60分万岁…… 代码概述 导入库及定义正则表达式 import urllib.request import urllib.error from bs4 import BeautifulSoup import re import xlwt import ssl # 定义正则语句 findlensinfo = re.compile(r'&lt;div class=&quot;item-title&quot;&gt;.*&gt;(.*?)&lt;/a&gt;') findlensprice = re.compile(r'&lt;div class=&quot;price price-now&quot;&gt;.*&gt;(.*?)&lt;/a&gt;') # 从lensinfo中拆解详细的焦距、光圈等信息 findcom = re.compile(r'.*?(?=[0-9])') findmm = re.compile(r'[0-9].*mm') findff = re.compile(r'mm(.*[0-9])') findother = re.compile(r'.*[0-9](.*)') 使用了三个函数 1 askURL——请求单个页面的数据' # 请求一个URL，将页面内容以字符串的形式返回 def askURL(url): head = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15&quot; } req = urllib.request.Request(url, headers=head) html = &quot;&quot; try: response = urllib.request.urlopen(req) html = response.read().decode(&quot;GBK&quot;) print(&quot;获取成功&quot;) except urllib.error.URLError as e: if hasattr(e, &quot;code&quot;): print(e.code) if hasattr(e, &quot;reason&quot;): print(e.reason) return html 2 getData——调用askURL并 # 根据基础URL，调用askURL函数，爬取所有相关的网页文件,并以列表返回解析后的数据 def getData(baseurl): datalist = [] for url in baseurl: htmlData = askURL(url) # 调用获取网页数据的函数 # 解析网页内容 soup = BeautifulSoup(htmlData, &quot;html.parser&quot;) for item in soup.find_all('li', class_=&quot;item&quot;): data = [] # 保存一个镜头的所有信息 item = str(item) lensinfo = re.findall(findlensinfo, item) if len(lensinfo) == 0: continue data.append(lensinfo[0]) try: data.append(re.findall(findcom,lensinfo[0])[0]) except IndexError: data.append(&quot;无法匹配到品牌&quot;) print(lensinfo,&quot;无法匹配到品牌&quot;) try: data.append(re.findall(findmm,lensinfo[0])[0]) except IndexError: data.append(&quot;无法匹配到焦距&quot;) print(lensinfo,&quot;无法匹配到焦距&quot;) try: data.append(re.findall(findff,lensinfo[0])[0]) except IndexError: data.append(&quot;无法匹配到光圈&quot;) print(lensinfo,&quot;无法匹配到光圈&quot;) try: data.append(re.findall(findother,lensinfo[0])[0]) except IndexError: data.append(&quot;无法匹配到其他型号信息&quot;) print(lensinfo,&quot;无法匹配到其他型号信息&quot;) lensprice = re.findall(findlensprice, item) if len(lensprice) != 0: data.append(lensprice[0].replace(&quot;¥&quot;, &quot;&quot;)) else: data.append(&quot;&quot;) datalist.append(data) return datalist 3 saveData——将数据保存到excel表 def saveData(datalist, savepath): book = xlwt.Workbook(encoding=&quot;utf-8&quot;) sheet = book.add_sheet(&quot;sheet1&quot;) col = (&quot;完整名称&quot;,&quot;制造商&quot;,&quot;焦距&quot;,&quot;光圈&quot;,&quot;其他型号信息&quot;,&quot;报价&quot;) count=len(datalist) for i in range(0, 6): sheet.write(0, i, col[i]) for i in range(0, count): print(&quot;第%d条&quot;%(i+1)) data=datalist[i] for j in range(0,6): sheet.write(i+1,j,data[j]) book.save(savepath) 主要执行部分 if __name__ == '__main__': ssl._create_default_https_context = ssl._create_unverified_context # 索尼E卡口 baseurl=[&quot;https://product.pconline.com.cn/lens/c11228_c15513/list.shtml&quot;,&quot;https://product.pconline.com.cn/lens/c11228_c15513/list_25s1.shtml&quot;,&quot;https://product.pconline.com.cn/lens/c11228_c15513/list_50s1.shtml&quot;,&quot;https://product.pconline.com.cn/lens/c11228_c15513/list_75s1.shtml&quot;] savepath = &quot;./sonylens.xls&quot; # M43画幅 # baseurl=[&quot;https://product.pconline.com.cn/lens/c11229/list.shtml&quot;,&quot;https://product.pconline.com.cn/lens/c11229/list_25s1.shtml&quot;] # savepath = &quot;./M43lens.xls&quot; datalist = getData(baseurl) saveData(datalist, savepath) 爬取结果 依次执行索尼E卡口和M43卡口的爬取，得到excel表格两个（下图均为整理后） 索尼E卡口爬取结果 M4/3卡口爬取结果 总结 由于获取到的镜头信息是一整段的如索尼 FE 200-600mm F5.6-6.3 G OSS，需要通过正则进行二次拆分。而由于各厂家的镜头信息差异较大，会存在匹配失败的情况。正则表达式的编写还需要精进。 M4/3镜头的焦距存在转换系数，如果能在存储之前处理，可以减少一些后期的工作。（后来另写了一小段代码，进行了转换） 爬完之后才发现，WIKI上有完整的镜头信息表格，本来直接复制就行了……（摔！） ","link":"https://sxk13.github.io/pmfun.github.io/post/wan-er-python-pa-qu-suo-ni-e-kou-he-m43-kou-jing-tou-lie-biao/"},{"title":"悠贝童书通-竞品调研","content":"这份文档是之前为幼儿绘本阅读产品所做的竞品调研。 悠贝是国内的亲子阅读服务机构，旗下包括悠贝亲子图书馆、悠贝童书通、悠贝家园共读三大业务以及亲子阅读线上平台、女性创业培训、专业阅读指导、儿童微剧、亲子文化研学、亲子文娱活动、儿童阅读课程、儿童场景营销、阅读公益活动等一系列业务组成的十二家生态公司，着力构建亲子产业生态圈。 微信小程序：悠贝童书通 IOS应用商店：童书通 官网：悠贝官网 总结 定位 线上小程序/APP中只有听绘本的功能，主要配合从线下悠贝图书馆中借阅的实体书使用。 付费点 VIP开通388/年，可获得绘本解析等扩展内容、解锁课程、获得超级书单、开通伴读萌宠等一系列围绕绘本的增值内容； 通过介绍文案、小程序数据不通等信息，推测线上会员与线下借阅会员无关，需分别购买。 特色功能 主要围绕绘本展开，包括深入分析绘本、游戏化陪读、家长课堂等，详细分析见下表。 可借鉴的点 定制化推荐：产品能个性化地满足用户需要时，用户会更难离开（艾尔弗雷德效应）； 脑科学认证+阅读报告：通过分析已读绘本，向家长宣传给孩子带来的提高，并据此给出下阶段的指导意见。 槽点 小程序与APP功能基本一致，但小程序中缺少礼品卡和邀请功能，且BUG较多； 录制故事只能在小程序中进行，并且需要跳转到另一个小程序（童书通助手）； 内部页面稍显混乱，如绘本精讲页面层级过深，同一功能的多个入口逻辑不清晰等问题，使用体验不够顺畅。 发展情况概览 1 发展历程 数据来源于悠贝官网 2009年悠贝成立，创建线下悠贝亲子图书馆，截至目前，线下图书馆3000家，覆盖300个城市。 2019年童书通APP上线，2019年11月，童书通用户量达181万，累计阅读量达260万，音频收听2000万次。 2 APP数据 数据来源：七麦数据 粗略判断APP和小程序的用户量比较多，但没有爆发式的增长，下载量比较稳定，可能由于本身定位就是配合线下图书馆使用的，APPStore上的评价中规中矩。 IOS端APP下载量仅在上线之初（19年12月前后）有较大幅度的上涨，之后无大幅波动的趋势；Android端有多个波峰，但都是单月突然上涨之后回落，猜测是数据统计周期的问题。 IOS：累计下载126,728，近30日日均下载153 Android：累计下载423,835，近30日日均下载320 微信小程序：1000+人最近使用 3 APP评价情况 IOS评分统计如下： 功能点分析 小程序和APP功能基本一致，主要功能点无差异，故后文不标注截图和功能描述来源。 1 功能结构 小程序功能结构如下 2 核心功能 配合线下借阅的实体绘本，在APP/小程序中听音频。 购买VIP后，家长可以听绘本解读、查看脑科学认证中的分析、并查看趣味问答等扩展内容。 听绘本：下列页面分别为绘本详情页、绘本播放页、VIP专享内容（右1+右2） 另：绘本下方的评论区，评论内容比较粗糙，有应付打卡任务的痕迹，也没有形成良好的社区氛围。 绘本借阅：点击绘本详情页左下角【去借书】，可查看附近的线下绘本馆和馆内图书在馆情况。 课程：课程数量不多，家长课堂和孩子用的课程混在一起。 3 其他功能 脑科学认证：强行分析每一本绘本激活大脑部分区块，展现每一次读绘本的作用。 积分商城：通过消费、参加打卡活动等方式获得积分，用积分兑换实体书。 排行榜：阅读天数、阅读本数、打卡天数等排行，激励用户持续使用。 萌宠伴读：开通会员后可以使用，通过读书打卡获得食物、衣服等，养育宠物。类似于变相的任务系统。 打卡活动：不限书籍类型，每天读书并发布评论，获得积分奖励。 直播：每天多场直播，首页进入可以查看今日直播时间表，直播内容有绘本和父母课堂等内容。 ","link":"https://sxk13.github.io/pmfun.github.io/post/you-bei-tong-shu-tong-jing-pin-diao-yan/"}]}